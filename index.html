<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Gesture Audio Score - Safe Load</title>
  <style>
    body { margin: 0; overflow: hidden; background: black; font-family: sans-serif; }
    #defaultCanvas0 { position: absolute; top: 0; left: 0; z-index: 1; }
    #startButton {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      font-size: 24px;
      padding: 1em 2em;
      background: #fff;
      border: none;
      cursor: pointer;
      z-index: 2;
    }
    video { display: none; }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/p5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/addons/p5.sound.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.8.31/Tone.min.js"></script>
</head>
<body>
<button id="startButton">Start App</button>
<video class="input_video" playsinline></video>
<script>
let meter, mic, handX = 0.5, handY = 0.5;
let hands, showScore = false;
let started = false;

window.onload = () => {
  const startButton = document.getElementById('startButton');
  startButton.addEventListener('click', async () => {
    if (!window.Tone) {
      alert("Tone.js not loaded yet. Try reloading the page.");
      return;
    }

    await Tone.start();
    console.log("Tone.js AudioContext started");

    document.getElementById('startButton').style.display = 'none';
    started = true;
    setupApp();
  });
};

function setupApp() {
  createCanvas(windowWidth, windowHeight);
  background(0);
  textAlign(CENTER, CENTER);
  textSize(24);
  fill(255);

  mic = new Tone.UserMedia();
  meter = new Tone.Meter();
  mic.open().then(() => {
    mic.connect(meter);
    mic.connect(new Tone.Gain(1).toDestination());
    console.log('Mic access granted');
  }).catch(e => {
    console.error('Mic access error:', e);
  });

  hands = new Hands({locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
  hands.setOptions({
    maxNumHands: 1,
    modelComplexity: 1,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.7
  });

  hands.onResults(results => {
    if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
      let indexTip = results.multiHandLandmarks[0][8];
      handX = indexTip.x;
      handY = indexTip.y;
      showScore = true;
    }
  });

  const videoElement = document.querySelector(".input_video");
  const camera = new Camera(videoElement, {
    onFrame: async () => {
      try {
        await hands.send({ image: videoElement });
      } catch (e) {
        console.error('Camera frame error:', e);
      }
    },
    width: 640,
    height: 480,
  });
  camera.start();
}

function draw() {
  if (!started) return;

  background(0, 20);

  if (!showScore || !meter) {
    fill(255);
    text("Waiting for mic and gesture input...", width / 2, height / 2);
    return;
  }

  const audioLevel = Math.abs(meter.getValue() || 0);
  const x = handX * width;
  const y = handY * height;

  noStroke();
  fill(255, 150, random(200, 255), map(audioLevel, 0, 0.5, 50, 200));
  ellipse(x + random(-20, 20), y + random(-20, 20), map(audioLevel, 0, 0.5, 20, 200));

  if (frameCount % 45 === 0 && audioLevel > 0.05) {
    fill(255);
    const type = floor(random(3));
    switch (type) {
      case 0: rect(x, y, 40, 4); break;
      case 1: triangle(x, y, x - 10, y + 15, x + 10, y + 15); break;
      case 2: line(x - 15, y, x + 15, y); break;
    }
  }
}
</script>
</body>
</html>
